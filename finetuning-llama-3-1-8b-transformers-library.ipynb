{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"60d09d2410494b468435396b0437ab44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b856f49431640d0afbd57f51818ce58","IPY_MODEL_658c73291c7a4fb3b7ba5daf0eefafc2","IPY_MODEL_fe1dce09ac7e42c3be5510ed95a036f1"],"layout":"IPY_MODEL_5d4b9fa54a18485dae497b8569d3f663"}},"0b856f49431640d0afbd57f51818ce58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7d048d997004170ae9ab8289552494c","placeholder":"​","style":"IPY_MODEL_fc06bbe6c3b54c4ab6f17b7e48c0e6da","value":"Map: 100%"}},"658c73291c7a4fb3b7ba5daf0eefafc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f95fdf8bb5c84e21b40cdee1be310dff","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_275ea7b1f0a8451aabdecaba396e48d1","value":500}},"fe1dce09ac7e42c3be5510ed95a036f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89f8e5926b9048049f249c16aeca6be7","placeholder":"​","style":"IPY_MODEL_974f1fde53d743fca56228f9ba788a20","value":" 500/500 [00:00&lt;00:00, 1238.41 examples/s]"}},"5d4b9fa54a18485dae497b8569d3f663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d048d997004170ae9ab8289552494c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc06bbe6c3b54c4ab6f17b7e48c0e6da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f95fdf8bb5c84e21b40cdee1be310dff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"275ea7b1f0a8451aabdecaba396e48d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89f8e5926b9048049f249c16aeca6be7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"974f1fde53d743fca56228f9ba788a20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1ac984d761c433f82be93131e744b4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec0be17f21cd4d479f2466e6501ae850","IPY_MODEL_939f973108b34c28a5df39d5497e8410","IPY_MODEL_7fdbfeb1e8604ca8a9dcaae186869a2c"],"layout":"IPY_MODEL_65322accc40f44f1b77ab4701addb5ac"}},"ec0be17f21cd4d479f2466e6501ae850":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6f42cb85fe2442ba26b29f3365a4084","placeholder":"​","style":"IPY_MODEL_79236205937e41dc95a82d5b97887daf","value":"Map: 100%"}},"939f973108b34c28a5df39d5497e8410":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54e9aa44e85f44e4bc67f02b0816fd01","max":1034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e65a3003b0a648b397391cc058de8f79","value":1034}},"7fdbfeb1e8604ca8a9dcaae186869a2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af18911c663a4375b73db97b004a3bea","placeholder":"​","style":"IPY_MODEL_142aa544e8c241cc9379ee726cd74b5c","value":" 1034/1034 [00:00&lt;00:00, 1735.68 examples/s]"}},"65322accc40f44f1b77ab4701addb5ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f42cb85fe2442ba26b29f3365a4084":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79236205937e41dc95a82d5b97887daf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54e9aa44e85f44e4bc67f02b0816fd01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e65a3003b0a648b397391cc058de8f79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af18911c663a4375b73db97b004a3bea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"142aa544e8c241cc9379ee726cd74b5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c1d670ff6fc4ff7bcf1cfcd98dac6c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c41cd3b7d70b4748b4358c87509f5904","IPY_MODEL_4b4aa7acc5d9468694700ce1e8c61fdc","IPY_MODEL_199b80d6a5d94659b7ef142a3b82a4d5"],"layout":"IPY_MODEL_3754d78d450f46b3800d19c4ec268605"}},"c41cd3b7d70b4748b4358c87509f5904":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8368a226dc40424ca70b9fe2f077c196","placeholder":"​","style":"IPY_MODEL_b025604aad26484989e6eeb2ae3dd7fd","value":"Loading checkpoint shards: 100%"}},"4b4aa7acc5d9468694700ce1e8c61fdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cfc1493906c419ab69a2ab0acd35bf5","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f77b16c8aec4af4afbb6760d89f84aa","value":4}},"199b80d6a5d94659b7ef142a3b82a4d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c3beaf7b6374a3493598ecca9160f55","placeholder":"​","style":"IPY_MODEL_14e16e8ae74f4ac2a4524c26583e845f","value":" 4/4 [01:19&lt;00:00, 17.12s/it]"}},"3754d78d450f46b3800d19c4ec268605":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8368a226dc40424ca70b9fe2f077c196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b025604aad26484989e6eeb2ae3dd7fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cfc1493906c419ab69a2ab0acd35bf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f77b16c8aec4af4afbb6760d89f84aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c3beaf7b6374a3493598ecca9160f55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14e16e8ae74f4ac2a4524c26583e845f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets peft accelerate","metadata":{"_uuid":"ca2b3e5e-3ef8-4dac-9b46-373451d3d3b0","_cell_guid":"cd03a35e-f199-45e0-9f08-044415db7417","collapsed":false,"id":"VRSBDK4WOiBc","outputId":"7ef71715-a24d-4538-9b84-8f5c1fbb135f","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U bitsandbytes --upgrade","metadata":{"_uuid":"8a46b281-c4e3-43a8-af33-a2b2ae804e4f","_cell_guid":"1e4a9404-f1f8-498c-b2d5-08ed9b111365","collapsed":false,"id":"cnbQtCD0BoEc","outputId":"6d6d05db-bbf2-4947-9c47-00ecdb51fc65","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install transformers --upgrade","metadata":{"_uuid":"e2f89bfd-0085-4009-859e-793c826c0896","_cell_guid":"8052f60f-3fa9-49bf-a9a4-0068932e2aa9","collapsed":false,"id":"sNe7vf5e__lr","outputId":"1fea4f98-4d78-49cb-b7d2-c11cee67006b","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['HUGGING_FACE_HUB_TOKEN'] = 'Your_Token_with_read_access'","metadata":{"_uuid":"353c77f3-66ee-44b2-bfd0-0dada71f1efa","_cell_guid":"4559dfd8-cbe0-4289-9859-94e76216e9fa","collapsed":false,"id":"hftttZe55Cnp","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:32.481019Z","iopub.execute_input":"2024-09-05T08:50:32.481619Z","iopub.status.idle":"2024-09-05T08:50:32.492910Z","shell.execute_reply.started":"2024-09-05T08:50:32.481571Z","shell.execute_reply":"2024-09-05T08:50:32.491891Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Imports\nimport random\nfrom datasets import load_dataset","metadata":{"_uuid":"302bf4ae-2e38-4f0c-94a8-5d0908993299","_cell_guid":"9053120f-1a02-4331-8acd-4bf0b5bc0fac","collapsed":false,"id":"-Whe_yOZZ161","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:33.391947Z","iopub.execute_input":"2024-09-05T08:50:33.392868Z","iopub.status.idle":"2024-09-05T08:50:34.955832Z","shell.execute_reply.started":"2024-09-05T08:50:33.392826Z","shell.execute_reply":"2024-09-05T08:50:34.954843Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"spider_dataset = load_dataset(\"spider\")","metadata":{"_uuid":"0cca9e6b-aec8-4387-b1d2-7f684357a6ca","_cell_guid":"2dccd716-e5ef-4b7e-82af-61a0c1e28da3","collapsed":false,"id":"vBj0cDPMONhC","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:34.957651Z","iopub.execute_input":"2024-09-05T08:50:34.958106Z","iopub.status.idle":"2024-09-05T08:50:38.463769Z","shell.execute_reply.started":"2024-09-05T08:50:34.958071Z","shell.execute_reply":"2024-09-05T08:50:38.462873Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/5.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f3a1af229734a7cb9217f4516e67586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/831k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4aece3f3bd470fb48fae7a8d12e30f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/126k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2041c186498e4a5fb9bb9bb19d637d11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e8e775e3824416cbf6f1e70106e9339"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1034 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94151250c9fd405b91de99196c24c7ab"}},"metadata":{}}]},{"cell_type":"code","source":"#Print the first sample of the training set\nprint (spider_dataset['train'][0])","metadata":{"_uuid":"1fee1969-9918-4921-88e3-7891360123c3","_cell_guid":"17826a91-e4a9-4989-8756-86fbfe34a19c","collapsed":false,"id":"rjF_MLo2OXLI","outputId":"a75b908e-2006-4ffe-8d51-7cd806f087c2","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.464849Z","iopub.execute_input":"2024-09-05T08:50:38.465320Z","iopub.status.idle":"2024-09-05T08:50:38.473209Z","shell.execute_reply.started":"2024-09-05T08:50:38.465286Z","shell.execute_reply":"2024-09-05T08:50:38.472267Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'db_id': 'department_management', 'query': 'SELECT count(*) FROM head WHERE age  >  56', 'question': 'How many heads of the departments are older than 56 ?', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'head', 'WHERE', 'age', '>', '56'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', 'value'], 'question_toks': ['How', 'many', 'heads', 'of', 'the', 'departments', 'are', 'older', 'than', '56', '?']}\n","output_type":"stream"}]},{"cell_type":"code","source":"#Print the first 10 sample of the training set\nprint(\"\\n\".join(str(spider_dataset['train'][i]) for i in range(10)))","metadata":{"_uuid":"97bfc88c-7232-4266-9c07-511b0f843e17","_cell_guid":"75b2af80-15c1-4956-a612-3c6245270a55","collapsed":false,"id":"wAq8Vt14R59o","outputId":"32cf74cd-0687-4c7d-c348-42b13c279fd3","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.475624Z","iopub.execute_input":"2024-09-05T08:50:38.476002Z","iopub.status.idle":"2024-09-05T08:50:38.486936Z","shell.execute_reply.started":"2024-09-05T08:50:38.475966Z","shell.execute_reply":"2024-09-05T08:50:38.485932Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'db_id': 'department_management', 'query': 'SELECT count(*) FROM head WHERE age  >  56', 'question': 'How many heads of the departments are older than 56 ?', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'head', 'WHERE', 'age', '>', '56'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'head', 'where', 'age', '>', 'value'], 'question_toks': ['How', 'many', 'heads', 'of', 'the', 'departments', 'are', 'older', 'than', '56', '?']}\n{'db_id': 'department_management', 'query': 'SELECT name ,  born_state ,  age FROM head ORDER BY age', 'question': 'List the name, born state and age of the heads of departments ordered by age.', 'query_toks': ['SELECT', 'name', ',', 'born_state', ',', 'age', 'FROM', 'head', 'ORDER', 'BY', 'age'], 'query_toks_no_value': ['select', 'name', ',', 'born_state', ',', 'age', 'from', 'head', 'order', 'by', 'age'], 'question_toks': ['List', 'the', 'name', ',', 'born', 'state', 'and', 'age', 'of', 'the', 'heads', 'of', 'departments', 'ordered', 'by', 'age', '.']}\n{'db_id': 'department_management', 'query': 'SELECT creation ,  name ,  budget_in_billions FROM department', 'question': 'List the creation year, name and budget of each department.', 'query_toks': ['SELECT', 'creation', ',', 'name', ',', 'budget_in_billions', 'FROM', 'department'], 'query_toks_no_value': ['select', 'creation', ',', 'name', ',', 'budget_in_billions', 'from', 'department'], 'question_toks': ['List', 'the', 'creation', 'year', ',', 'name', 'and', 'budget', 'of', 'each', 'department', '.']}\n{'db_id': 'department_management', 'query': 'SELECT max(budget_in_billions) ,  min(budget_in_billions) FROM department', 'question': 'What are the maximum and minimum budget of the departments?', 'query_toks': ['SELECT', 'max', '(', 'budget_in_billions', ')', ',', 'min', '(', 'budget_in_billions', ')', 'FROM', 'department'], 'query_toks_no_value': ['select', 'max', '(', 'budget_in_billions', ')', ',', 'min', '(', 'budget_in_billions', ')', 'from', 'department'], 'question_toks': ['What', 'are', 'the', 'maximum', 'and', 'minimum', 'budget', 'of', 'the', 'departments', '?']}\n{'db_id': 'department_management', 'query': 'SELECT avg(num_employees) FROM department WHERE ranking BETWEEN 10 AND 15', 'question': 'What is the average number of employees of the departments whose rank is between 10 and 15?', 'query_toks': ['SELECT', 'avg', '(', 'num_employees', ')', 'FROM', 'department', 'WHERE', 'ranking', 'BETWEEN', '10', 'AND', '15'], 'query_toks_no_value': ['select', 'avg', '(', 'num_employees', ')', 'from', 'department', 'where', 'ranking', 'between', 'value', 'and', 'value'], 'question_toks': ['What', 'is', 'the', 'average', 'number', 'of', 'employees', 'of', 'the', 'departments', 'whose', 'rank', 'is', 'between', '10', 'and', '15', '?']}\n{'db_id': 'department_management', 'query': \"SELECT name FROM head WHERE born_state != 'California'\", 'question': 'What are the names of the heads who are born outside the California state?', 'query_toks': ['SELECT', 'name', 'FROM', 'head', 'WHERE', 'born_state', '!', '=', \"'California\", \"'\"], 'query_toks_no_value': ['select', 'name', 'from', 'head', 'where', 'born_state', '!', '=', 'value'], 'question_toks': ['What', 'are', 'the', 'names', 'of', 'the', 'heads', 'who', 'are', 'born', 'outside', 'the', 'California', 'state', '?']}\n{'db_id': 'department_management', 'query': \"SELECT DISTINCT T1.creation FROM department AS T1 JOIN management AS T2 ON T1.department_id  =  T2.department_id JOIN head AS T3 ON T2.head_id  =  T3.head_id WHERE T3.born_state  =  'Alabama'\", 'question': \"What are the distinct creation years of the departments managed by a secretary born in state 'Alabama'?\", 'query_toks': ['SELECT', 'DISTINCT', 'T1.creation', 'FROM', 'department', 'AS', 'T1', 'JOIN', 'management', 'AS', 'T2', 'ON', 'T1.department_id', '=', 'T2.department_id', 'JOIN', 'head', 'AS', 'T3', 'ON', 'T2.head_id', '=', 'T3.head_id', 'WHERE', 'T3.born_state', '=', \"'Alabama\", \"'\"], 'query_toks_no_value': ['select', 'distinct', 't1', '.', 'creation', 'from', 'department', 'as', 't1', 'join', 'management', 'as', 't2', 'on', 't1', '.', 'department_id', '=', 't2', '.', 'department_id', 'join', 'head', 'as', 't3', 'on', 't2', '.', 'head_id', '=', 't3', '.', 'head_id', 'where', 't3', '.', 'born_state', '=', 'value'], 'question_toks': ['What', 'are', 'the', 'distinct', 'creation', 'years', 'of', 'the', 'departments', 'managed', 'by', 'a', 'secretary', 'born', 'in', 'state', \"'Alabama\", \"'\", '?']}\n{'db_id': 'department_management', 'query': 'SELECT born_state FROM head GROUP BY born_state HAVING count(*)  >=  3', 'question': 'What are the names of the states where at least 3 heads were born?', 'query_toks': ['SELECT', 'born_state', 'FROM', 'head', 'GROUP', 'BY', 'born_state', 'HAVING', 'count', '(', '*', ')', '>', '=', '3'], 'query_toks_no_value': ['select', 'born_state', 'from', 'head', 'group', 'by', 'born_state', 'having', 'count', '(', '*', ')', '>', '=', 'value'], 'question_toks': ['What', 'are', 'the', 'names', 'of', 'the', 'states', 'where', 'at', 'least', '3', 'heads', 'were', 'born', '?']}\n{'db_id': 'department_management', 'query': 'SELECT creation FROM department GROUP BY creation ORDER BY count(*) DESC LIMIT 1', 'question': 'In which year were most departments established?', 'query_toks': ['SELECT', 'creation', 'FROM', 'department', 'GROUP', 'BY', 'creation', 'ORDER', 'BY', 'count', '(', '*', ')', 'DESC', 'LIMIT', '1'], 'query_toks_no_value': ['select', 'creation', 'from', 'department', 'group', 'by', 'creation', 'order', 'by', 'count', '(', '*', ')', 'desc', 'limit', 'value'], 'question_toks': ['In', 'which', 'year', 'were', 'most', 'departments', 'established', '?']}\n{'db_id': 'department_management', 'query': \"SELECT T1.name ,  T1.num_employees FROM department AS T1 JOIN management AS T2 ON T1.department_id  =  T2.department_id WHERE T2.temporary_acting  =  'Yes'\", 'question': \"Show the name and number of employees for the departments managed by heads whose temporary acting value is 'Yes'?\", 'query_toks': ['SELECT', 'T1.name', ',', 'T1.num_employees', 'FROM', 'department', 'AS', 'T1', 'JOIN', 'management', 'AS', 'T2', 'ON', 'T1.department_id', '=', 'T2.department_id', 'WHERE', 'T2.temporary_acting', '=', \"'Yes\", \"'\"], 'query_toks_no_value': ['select', 't1', '.', 'name', ',', 't1', '.', 'num_employees', 'from', 'department', 'as', 't1', 'join', 'management', 'as', 't2', 'on', 't1', '.', 'department_id', '=', 't2', '.', 'department_id', 'where', 't2', '.', 'temporary_acting', '=', 'value'], 'question_toks': ['Show', 'the', 'name', 'and', 'number', 'of', 'employees', 'for', 'the', 'departments', 'managed', 'by', 'heads', 'whose', 'temporary', 'acting', 'value', 'is', \"'Yes\", \"'\", '?']}\n","output_type":"stream"}]},{"cell_type":"code","source":"#Print total number of rows in the training set\nnum_rows = len(spider_dataset[\"train\"])\nprint(f\"Number of rows in the training split: {num_rows}\")","metadata":{"_uuid":"7270bf0a-8cbb-449d-afd4-046d66ae93df","_cell_guid":"73d2a0cb-28e7-4538-9b05-c4948d419b5c","collapsed":false,"id":"ueXW0zrvPQ-_","outputId":"ecc769e5-3712-4a3d-b47f-e560f6c8884f","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.487934Z","iopub.execute_input":"2024-09-05T08:50:38.488319Z","iopub.status.idle":"2024-09-05T08:50:38.495118Z","shell.execute_reply.started":"2024-09-05T08:50:38.488284Z","shell.execute_reply":"2024-09-05T08:50:38.494208Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of rows in the training split: 7000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Print the first 10 sample of the validation set\nvalidation_set = spider_dataset['validation']\nprint(\"\\n\".join(str(validation_set[i]) for i in range(10)))","metadata":{"_uuid":"36966dcd-d9da-4e10-9476-524ee5dbafca","_cell_guid":"7192cea3-9352-485c-8ebc-a6b41f96f102","collapsed":false,"id":"UdffSboBP-tv","outputId":"5068e076-ef1e-4337-f4a3-71b8d4e15523","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.496225Z","iopub.execute_input":"2024-09-05T08:50:38.496553Z","iopub.status.idle":"2024-09-05T08:50:38.506722Z","shell.execute_reply.started":"2024-09-05T08:50:38.496520Z","shell.execute_reply":"2024-09-05T08:50:38.505753Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'db_id': 'concert_singer', 'query': 'SELECT count(*) FROM singer', 'question': 'How many singers do we have?', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'singer'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'singer'], 'question_toks': ['How', 'many', 'singers', 'do', 'we', 'have', '?']}\n{'db_id': 'concert_singer', 'query': 'SELECT count(*) FROM singer', 'question': 'What is the total number of singers?', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'singer'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'singer'], 'question_toks': ['What', 'is', 'the', 'total', 'number', 'of', 'singers', '?']}\n{'db_id': 'concert_singer', 'query': 'SELECT name ,  country ,  age FROM singer ORDER BY age DESC', 'question': 'Show name, country, age for all singers ordered by age from the oldest to the youngest.', 'query_toks': ['SELECT', 'name', ',', 'country', ',', 'age', 'FROM', 'singer', 'ORDER', 'BY', 'age', 'DESC'], 'query_toks_no_value': ['select', 'name', ',', 'country', ',', 'age', 'from', 'singer', 'order', 'by', 'age', 'desc'], 'question_toks': ['Show', 'name', ',', 'country', ',', 'age', 'for', 'all', 'singers', 'ordered', 'by', 'age', 'from', 'the', 'oldest', 'to', 'the', 'youngest', '.']}\n{'db_id': 'concert_singer', 'query': 'SELECT name ,  country ,  age FROM singer ORDER BY age DESC', 'question': 'What are the names, countries, and ages for every singer in descending order of age?', 'query_toks': ['SELECT', 'name', ',', 'country', ',', 'age', 'FROM', 'singer', 'ORDER', 'BY', 'age', 'DESC'], 'query_toks_no_value': ['select', 'name', ',', 'country', ',', 'age', 'from', 'singer', 'order', 'by', 'age', 'desc'], 'question_toks': ['What', 'are', 'the', 'names', ',', 'countries', ',', 'and', 'ages', 'for', 'every', 'singer', 'in', 'descending', 'order', 'of', 'age', '?']}\n{'db_id': 'concert_singer', 'query': \"SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\", 'question': 'What is the average, minimum, and maximum age of all singers from France?', 'query_toks': ['SELECT', 'avg', '(', 'age', ')', ',', 'min', '(', 'age', ')', ',', 'max', '(', 'age', ')', 'FROM', 'singer', 'WHERE', 'country', '=', \"'France\", \"'\"], 'query_toks_no_value': ['select', 'avg', '(', 'age', ')', ',', 'min', '(', 'age', ')', ',', 'max', '(', 'age', ')', 'from', 'singer', 'where', 'country', '=', 'value'], 'question_toks': ['What', 'is', 'the', 'average', ',', 'minimum', ',', 'and', 'maximum', 'age', 'of', 'all', 'singers', 'from', 'France', '?']}\n{'db_id': 'concert_singer', 'query': \"SELECT avg(age) ,  min(age) ,  max(age) FROM singer WHERE country  =  'France'\", 'question': 'What is the average, minimum, and maximum age for all French singers?', 'query_toks': ['SELECT', 'avg', '(', 'age', ')', ',', 'min', '(', 'age', ')', ',', 'max', '(', 'age', ')', 'FROM', 'singer', 'WHERE', 'country', '=', \"'France\", \"'\"], 'query_toks_no_value': ['select', 'avg', '(', 'age', ')', ',', 'min', '(', 'age', ')', ',', 'max', '(', 'age', ')', 'from', 'singer', 'where', 'country', '=', 'value'], 'question_toks': ['What', 'is', 'the', 'average', ',', 'minimum', ',', 'and', 'maximum', 'age', 'for', 'all', 'French', 'singers', '?']}\n{'db_id': 'concert_singer', 'query': 'SELECT song_name ,  song_release_year FROM singer ORDER BY age LIMIT 1', 'question': 'Show the name and the release year of the song by the youngest singer.', 'query_toks': ['SELECT', 'song_name', ',', 'song_release_year', 'FROM', 'singer', 'ORDER', 'BY', 'age', 'LIMIT', '1'], 'query_toks_no_value': ['select', 'song_name', ',', 'song_release_year', 'from', 'singer', 'order', 'by', 'age', 'limit', 'value'], 'question_toks': ['Show', 'the', 'name', 'and', 'the', 'release', 'year', 'of', 'the', 'song', 'by', 'the', 'youngest', 'singer', '.']}\n{'db_id': 'concert_singer', 'query': 'SELECT song_name ,  song_release_year FROM singer ORDER BY age LIMIT 1', 'question': 'What are the names and release years for all the songs of the youngest singer?', 'query_toks': ['SELECT', 'song_name', ',', 'song_release_year', 'FROM', 'singer', 'ORDER', 'BY', 'age', 'LIMIT', '1'], 'query_toks_no_value': ['select', 'song_name', ',', 'song_release_year', 'from', 'singer', 'order', 'by', 'age', 'limit', 'value'], 'question_toks': ['What', 'are', 'the', 'names', 'and', 'release', 'years', 'for', 'all', 'the', 'songs', 'of', 'the', 'youngest', 'singer', '?']}\n{'db_id': 'concert_singer', 'query': 'SELECT DISTINCT country FROM singer WHERE age  >  20', 'question': 'What are all distinct countries where singers above age 20 are from?', 'query_toks': ['SELECT', 'DISTINCT', 'country', 'FROM', 'singer', 'WHERE', 'age', '>', '20'], 'query_toks_no_value': ['select', 'distinct', 'country', 'from', 'singer', 'where', 'age', '>', 'value'], 'question_toks': ['What', 'are', 'all', 'distinct', 'countries', 'where', 'singers', 'above', 'age', '20', 'are', 'from', '?']}\n{'db_id': 'concert_singer', 'query': 'SELECT DISTINCT country FROM singer WHERE age  >  20', 'question': 'What are  the different countries with singers above age 20?', 'query_toks': ['SELECT', 'DISTINCT', 'country', 'FROM', 'singer', 'WHERE', 'age', '>', '20'], 'query_toks_no_value': ['select', 'distinct', 'country', 'from', 'singer', 'where', 'age', '>', 'value'], 'question_toks': ['What', 'are', 'the', 'different', 'countries', 'with', 'singers', 'above', 'age', '20', '?']}\n","output_type":"stream"}]},{"cell_type":"code","source":"#Print total number of rows in the validation set\nnum_rows = len(validation_set)\nprint(f\"Number of rows in the validation split: {num_rows}\")","metadata":{"_uuid":"50484f09-adb0-48a4-a487-f56c80c75a9b","_cell_guid":"9a393d8d-6c11-4f74-98d5-7bdbb50f2aa4","collapsed":false,"id":"eDRn13yLZBFR","outputId":"1c2748c1-686e-422a-f699-8c6d5c002a33","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.507897Z","iopub.execute_input":"2024-09-05T08:50:38.508298Z","iopub.status.idle":"2024-09-05T08:50:38.514624Z","shell.execute_reply.started":"2024-09-05T08:50:38.508248Z","shell.execute_reply":"2024-09-05T08:50:38.513696Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of rows in the validation split: 1034\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Randomly sampling the training set\n\nTo expedite experimentation and manage resource constraints, we'll create a smaller, randomly sampled dataset from the original Spider training set. This approach reduces training time for large language models like Llama 3.1, making it feasible to run experiments on platforms with limited resources. This smaller dataset can be used for initial model training and evaluation before potentially scaling up to the full training set.","metadata":{"_uuid":"50310ea4-43c0-4404-b4a6-afa14e5513a1","_cell_guid":"f80fa33c-8d40-4d61-8b12-0ca77124e985","id":"DIcjd4x8bJKi","trusted":true}},{"cell_type":"code","source":"#Randomly sample training set\ntrain_dataset = spider_dataset[\"train\"]\n\n# Set the number of random samples you want\nnum_samples = 500\n\n# Get a list of random indices\nrandom_indices = random.sample(range(len(train_dataset)), num_samples)\n\n# Create a new dataset with the random samples\nsampled_train = train_dataset.select(random_indices)\n\n# Now you can use 'random_dataset' for training\nprint(f\"Number of rows in the randomly sampled train dataset: {len(sampled_train)}\")","metadata":{"_uuid":"ff6d606a-eb3b-4b50-8371-56ef00d42121","_cell_guid":"3e58e67a-b1fd-4f99-a5a6-de6de4f8ab17","collapsed":false,"id":"4bFPAVOCZgzc","outputId":"a46f2b5e-f4c5-40c2-f132-0f8ac27ab830","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.515876Z","iopub.execute_input":"2024-09-05T08:50:38.516184Z","iopub.status.idle":"2024-09-05T08:50:38.535693Z","shell.execute_reply.started":"2024-09-05T08:50:38.516132Z","shell.execute_reply":"2024-09-05T08:50:38.534611Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Number of rows in the randomly sampled train dataset: 500\n","output_type":"stream"}]},{"cell_type":"code","source":"#Print the first 10 sample of the sampled train set\nprint(\"\\n\".join(str(sampled_train[i]) for i in range(10)))","metadata":{"_uuid":"dd3279b7-1041-4209-b858-179de9ee7b2b","_cell_guid":"a6f3d8a1-c1ba-48fc-9b89-77ae85c9b8e8","collapsed":false,"id":"WAVOe58zaUNA","outputId":"d38700d3-6854-4ffb-fbe1-ffa6f9452059","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.536794Z","iopub.execute_input":"2024-09-05T08:50:38.537440Z","iopub.status.idle":"2024-09-05T08:50:38.547348Z","shell.execute_reply.started":"2024-09-05T08:50:38.537399Z","shell.execute_reply":"2024-09-05T08:50:38.546299Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'db_id': 'formula_1', 'query': 'SELECT DISTINCT T1.forename FROM drivers AS T1 JOIN driverstandings AS T2 ON T1.driverid = T2.driverid WHERE T2.position = 1 AND T2.wins = 1', 'question': 'What are all the different first names of the drivers who are in position as standing and won?', 'query_toks': ['SELECT', 'DISTINCT', 'T1.forename', 'FROM', 'drivers', 'AS', 'T1', 'JOIN', 'driverstandings', 'AS', 'T2', 'ON', 'T1.driverid', '=', 'T2.driverid', 'WHERE', 'T2.position', '=', '1', 'AND', 'T2.wins', '=', '1'], 'query_toks_no_value': ['select', 'distinct', 't1', '.', 'forename', 'from', 'drivers', 'as', 't1', 'join', 'driverstandings', 'as', 't2', 'on', 't1', '.', 'driverid', '=', 't2', '.', 'driverid', 'where', 't2', '.', 'position', '=', 'value', 'and', 't2', '.', 'wins', '=', 'value'], 'question_toks': ['What', 'are', 'all', 'the', 'different', 'first', 'names', 'of', 'the', 'drivers', 'who', 'are', 'in', 'position', 'as', 'standing', 'and', 'won', '?']}\n{'db_id': 'activity_1', 'query': 'SELECT T1.fname ,  T1.lname FROM Faculty AS T1 JOIN Student AS T2 ON T1.FacID  =  T2.advisor GROUP BY T1.FacID ORDER BY count(*) DESC LIMIT 1', 'question': 'What are the first and last name of the faculty who has the most students?', 'query_toks': ['SELECT', 'T1.fname', ',', 'T1.lname', 'FROM', 'Faculty', 'AS', 'T1', 'JOIN', 'Student', 'AS', 'T2', 'ON', 'T1.FacID', '=', 'T2.advisor', 'GROUP', 'BY', 'T1.FacID', 'ORDER', 'BY', 'count', '(', '*', ')', 'DESC', 'LIMIT', '1'], 'query_toks_no_value': ['select', 't1', '.', 'fname', ',', 't1', '.', 'lname', 'from', 'faculty', 'as', 't1', 'join', 'student', 'as', 't2', 'on', 't1', '.', 'facid', '=', 't2', '.', 'advisor', 'group', 'by', 't1', '.', 'facid', 'order', 'by', 'count', '(', '*', ')', 'desc', 'limit', 'value'], 'question_toks': ['What', 'are', 'the', 'first', 'and', 'last', 'name', 'of', 'the', 'faculty', 'who', 'has', 'the', 'most', 'students', '?']}\n{'db_id': 'student_assessment', 'query': 'SELECT T2.candidate_id FROM people AS T1 JOIN candidates AS T2 ON T1.person_id = T2.candidate_id WHERE T1.email_address = \"stanley.monahan@example.org\"', 'question': 'Find id of the candidate whose email is stanley.monahan@example.org?', 'query_toks': ['SELECT', 'T2.candidate_id', 'FROM', 'people', 'AS', 'T1', 'JOIN', 'candidates', 'AS', 'T2', 'ON', 'T1.person_id', '=', 'T2.candidate_id', 'WHERE', 'T1.email_address', '=', '``', 'stanley.monahan', '@', 'example.org', \"''\"], 'query_toks_no_value': ['select', 't2', '.', 'candidate_id', 'from', 'people', 'as', 't1', 'join', 'candidates', 'as', 't2', 'on', 't1', '.', 'person_id', '=', 't2', '.', 'candidate_id', 'where', 't1', '.', 'email_address', '=', 'value'], 'question_toks': ['Find', 'id', 'of', 'the', 'candidate', 'whose', 'email', 'is', 'stanley.monahan', '@', 'example.org', '?']}\n{'db_id': 'pilot_record', 'query': 'SELECT count(*) FROM pilot', 'question': 'How many pilots are there?', 'query_toks': ['SELECT', 'count', '(', '*', ')', 'FROM', 'pilot'], 'query_toks_no_value': ['select', 'count', '(', '*', ')', 'from', 'pilot'], 'question_toks': ['How', 'many', 'pilots', 'are', 'there', '?']}\n{'db_id': 'student_assessment', 'query': 'SELECT student_id FROM student_course_attendance WHERE course_id = 301 ORDER BY date_of_attendance DESC LIMIT 1', 'question': 'What are the ids of the students who registered for course 301 most recently?', 'query_toks': ['SELECT', 'student_id', 'FROM', 'student_course_attendance', 'WHERE', 'course_id', '=', '301', 'ORDER', 'BY', 'date_of_attendance', 'DESC', 'LIMIT', '1'], 'query_toks_no_value': ['select', 'student_id', 'from', 'student_course_attendance', 'where', 'course_id', '=', 'value', 'order', 'by', 'date_of_attendance', 'desc', 'limit', 'value'], 'question_toks': ['What', 'are', 'the', 'ids', 'of', 'the', 'students', 'who', 'registered', 'for', 'course', '301', 'most', 'recently', '?']}\n{'db_id': 'party_host', 'query': 'SELECT Nationality FROM HOST GROUP BY Nationality ORDER BY COUNT(*) DESC LIMIT 1', 'question': 'Show the most common nationality of hosts.', 'query_toks': ['SELECT', 'Nationality', 'FROM', 'HOST', 'GROUP', 'BY', 'Nationality', 'ORDER', 'BY', 'COUNT', '(', '*', ')', 'DESC', 'LIMIT', '1'], 'query_toks_no_value': ['select', 'nationality', 'from', 'host', 'group', 'by', 'nationality', 'order', 'by', 'count', '(', '*', ')', 'desc', 'limit', 'value'], 'question_toks': ['Show', 'the', 'most', 'common', 'nationality', 'of', 'hosts', '.']}\n{'db_id': 'tracking_orders', 'query': 'SELECT T1.customer_name FROM customers AS T1 JOIN orders AS T2 ON T1.customer_id = T2.customer_id GROUP BY T1.customer_id ORDER BY count(*) DESC LIMIT 1', 'question': 'What is the name of the customer who has the largest number of orders?', 'query_toks': ['SELECT', 'T1.customer_name', 'FROM', 'customers', 'AS', 'T1', 'JOIN', 'orders', 'AS', 'T2', 'ON', 'T1.customer_id', '=', 'T2.customer_id', 'GROUP', 'BY', 'T1.customer_id', 'ORDER', 'BY', 'count', '(', '*', ')', 'DESC', 'LIMIT', '1'], 'query_toks_no_value': ['select', 't1', '.', 'customer_name', 'from', 'customers', 'as', 't1', 'join', 'orders', 'as', 't2', 'on', 't1', '.', 'customer_id', '=', 't2', '.', 'customer_id', 'group', 'by', 't1', '.', 'customer_id', 'order', 'by', 'count', '(', '*', ')', 'desc', 'limit', 'value'], 'question_toks': ['What', 'is', 'the', 'name', 'of', 'the', 'customer', 'who', 'has', 'the', 'largest', 'number', 'of', 'orders', '?']}\n{'db_id': 'customers_and_invoices', 'query': 'SELECT gender ,  count(*) FROM Customers GROUP BY gender', 'question': 'Show the number of customers for each gender.', 'query_toks': ['SELECT', 'gender', ',', 'count', '(', '*', ')', 'FROM', 'Customers', 'GROUP', 'BY', 'gender'], 'query_toks_no_value': ['select', 'gender', ',', 'count', '(', '*', ')', 'from', 'customers', 'group', 'by', 'gender'], 'question_toks': ['Show', 'the', 'number', 'of', 'customers', 'for', 'each', 'gender', '.']}\n{'db_id': 'program_share', 'query': 'SELECT name FROM channel ORDER BY rating_in_percent DESC', 'question': 'Give me a list of all the channel names sorted by the channel rating in descending order.', 'query_toks': ['SELECT', 'name', 'FROM', 'channel', 'ORDER', 'BY', 'rating_in_percent', 'DESC'], 'query_toks_no_value': ['select', 'name', 'from', 'channel', 'order', 'by', 'rating_in_percent', 'desc'], 'question_toks': ['Give', 'me', 'a', 'list', 'of', 'all', 'the', 'channel', 'names', 'sorted', 'by', 'the', 'channel', 'rating', 'in', 'descending', 'order', '.']}\n{'db_id': 'insurance_policies', 'query': 'SELECT Date_Claim_Made FROM Claims WHERE Amount_Settled  <=  ( SELECT avg(Amount_Settled) FROM Claims )', 'question': 'Among all the claims, which settlements have a claimed amount that is no more than the average? List the claim start date.', 'query_toks': ['SELECT', 'Date_Claim_Made', 'FROM', 'Claims', 'WHERE', 'Amount_Settled', '<', '=', '(', 'SELECT', 'avg', '(', 'Amount_Settled', ')', 'FROM', 'Claims', ')'], 'query_toks_no_value': ['select', 'date_claim_made', 'from', 'claims', 'where', 'amount_settled', '<', '=', '(', 'select', 'avg', '(', 'amount_settled', ')', 'from', 'claims', ')'], 'question_toks': ['Among', 'all', 'the', 'claims', ',', 'which', 'settlements', 'have', 'a', 'claimed', 'amount', 'that', 'is', 'no', 'more', 'than', 'the', 'average', '?', 'List', 'the', 'claim', 'start', 'date', '.']}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Check for any inconsistencies in the datasets\n\nThe following code cell checks for potential inconsistencies in the randomly sampled training set (sampled_train) and the validation set (validation_set). It verifies if any questions or their corresponding SQL queries are empty, which could indicate data errors or annotation issues. Identifying and addressing these inconsistencies before fine-tuning is crucial to ensure the model is trained on reliable data, leading to better performance and preventing unexpected behavior.","metadata":{"_uuid":"6463a3ea-618d-49d6-87d2-6fb2f7608f13","_cell_guid":"c58d1366-1fcd-40ba-8c53-d53bdb2bdbe1","id":"M-MMaEEwhP4L","trusted":true}},{"cell_type":"code","source":"def check_dataset_inconsistencies(dataset, split_name):\n    \"\"\"\n    Checks for inconsistencies in the Spider dataset, such as empty questions or queries.\n\n    Args:\n        dataset: The Hugging Face dataset object.\n        split_name: The name of the split (e.g., \"train\", \"validation\").\n    \"\"\"\n\n    num_inconsistencies = 0\n    for i, example in enumerate(dataset):\n        if not example[\"question\"].strip() or not example[\"query\"].strip():\n            print(f\"Inconsistency found in {split_name} split, example {i}:\")\n            print(f\"  Question: {example['question']}\")\n            print(f\"  Query: {example['query']}\")\n            num_inconsistencies += 1\n\n    print(f\"Total inconsistencies found in {split_name} split: {num_inconsistencies}\")\n\n\n# Call the function:\ncheck_dataset_inconsistencies(sampled_train, \"sampled_train\")\ncheck_dataset_inconsistencies(validation_set, \"validation\")","metadata":{"_uuid":"fc3e8956-c625-4d6c-8fa4-3f65899e63b6","_cell_guid":"e14a4ffe-06ab-4a95-ac46-28573f6f67d6","collapsed":false,"id":"eUBIKKEpaY2p","outputId":"3aa38043-fb9d-41b2-f877-2d003fc7c7ce","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:38.550307Z","iopub.execute_input":"2024-09-05T08:50:38.550830Z","iopub.status.idle":"2024-09-05T08:50:38.831387Z","shell.execute_reply.started":"2024-09-05T08:50:38.550799Z","shell.execute_reply":"2024-09-05T08:50:38.830529Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Total inconsistencies found in sampled_train split: 0\nTotal inconsistencies found in validation split: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Analyzing Sequence Lengths and Determining Maximum Sequence Length\n\nThis code analyzes the distribution of question and query lengths in the sampled_train dataset after tokenization with the Llama 3.1 tokenizer. This analysis is crucial for determining an appropriate max_length parameter for padding and truncating sequences during the fine-tuning process.\nThe code performs the following:\nTokenization and Length Calculation: It tokenizes the questions and queries in the dataset using the Llama 3.1 tokenizer and calculates the length of each tokenized sequence.\nVisualization: It generates histograms to visualize the distribution of question lengths and query lengths. These histograms provide a visual understanding of the typical lengths and the presence of outliers.\nPercentile Calculation: It calculates key percentiles (90th, 95th, 98th, and 99th) for both question and query lengths. These percentiles provide a numerical representation of the length distribution, indicating the lengths below which a certain percentage of the data falls.\nDetermining max_length: The code then identifies the maximum value between the 99th percentile of question lengths and the 99th percentile of query lengths. This value is multiplied by 1.1 to provide a buffer and ensure that the chosen max_length accommodates at least 99% of both the questions and queries, minimizing the risk of information loss due to truncation.\nBy analyzing the sequence length distribution and carefully selecting the max_length, we aim to balance data coverage, computational efficiency, and the model's ability to process information effectively during fine-tuning.","metadata":{"_uuid":"9f4d47ba-0648-4e3f-b2b8-a091a72ef462","_cell_guid":"29a8bbc2-a322-42a4-b95a-25eac191045f","id":"Sb2pKe5ExJhR","trusted":true}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", token=os.environ[\"HUGGING_FACE_HUB_TOKEN\"])\n\ndef analyze_sequence_lengths(dataset, tokenizer):\n    \"\"\"\n    Analyzes the distribution of sequence lengths in a dataset after tokenization.\n\n    Args:\n        dataset: The Hugging Face dataset to analyze.\n        tokenizer: The tokenizer to use for tokenization.\n    \"\"\"\n\n    question_lengths = []\n    query_lengths = []\n\n    for example in dataset:\n        question_tokens = tokenizer.tokenize(example[\"question\"])\n        query_tokens = tokenizer.tokenize(example[\"query\"])\n        question_lengths.append(len(question_tokens))\n        query_lengths.append(len(query_tokens))\n\n    # Plot histograms of sequence lengths\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.hist(question_lengths, bins=50)\n    plt.title(\"Question Lengths\")\n    plt.xlabel(\"Number of Tokens\")\n    plt.ylabel(\"Frequency\")\n\n    plt.subplot(1, 2, 2)\n    plt.hist(query_lengths, bins=50)\n    plt.title(\"Query Lengths\")\n    plt.xlabel(\"Number of Tokens\")\n    plt.ylabel(\"Frequency\")\n\n    plt.tight_layout()\n    plt.show()\n\n    # Calculate percentiles\n    for percentile in [90, 95, 98, 99]:\n        q_percentile = np.percentile(question_lengths, percentile)\n        sql_percentile = np.percentile(query_lengths, percentile)\n        print(f\"{percentile}th percentile of question lengths: {q_percentile}\")\n        print(f\"{percentile}th percentile of query lengths: {sql_percentile}\")\n\n    max_99th_percentile = int(\n    max(\n        np.percentile(question_lengths, 99),\n        np.percentile(query_lengths, 99),\n    )\n    )\n    print(f\"Maximum of 99th percentiles: {max_99th_percentile}\")\n    return max_99th_percentile\n\n\n# Calling the function:\nmax_99th_percentile = analyze_sequence_lengths(sampled_train, tokenizer)\nmax_length = int(1.1 * max_99th_percentile)\nprint(f\"max_length: {max_length}\")","metadata":{"_uuid":"7f77abb5-77ec-4012-a9a5-b596bc06cd9b","_cell_guid":"e9e7bfa6-6465-40ec-9ea9-fd03461821da","collapsed":false,"id":"8t_wRH95xhdT","outputId":"0ec64106-e334-4a9f-9b00-5227e4d9caf5","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:39.295134Z","iopub.execute_input":"2024-09-05T08:50:39.295530Z","iopub.status.idle":"2024-09-05T08:50:44.706916Z","shell.execute_reply.started":"2024-09-05T08:50:39.295493Z","shell.execute_reply":"2024-09-05T08:50:44.705947Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdfcda4ace2345319e53e3495450e9cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ecc0ef6cabb446e8ceac1115240bad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c1c315e353a4f469de0f1518ad44315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"90th percentile of question lengths: 21.0\n90th percentile of query lengths: 56.10000000000002\n95th percentile of question lengths: 24.0\n95th percentile of query lengths: 68.0\n98th percentile of question lengths: 27.0\n98th percentile of query lengths: 88.19999999999982\n99th percentile of question lengths: 28.0\n99th percentile of query lengths: 120.02999999999997\nMaximum of 99th percentiles: 120\nmax_length: 132\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the Llama 3.1 8B Instruct tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", token=os.environ[\"HUGGING_FACE_HUB_TOKEN\"])\ntokenizer.pad_token = tokenizer.eos_token\n\ndef tokenize_function(examples):\n  \"\"\"\n  Tokenizes the questions and SQL queries in a batch of examples.\n  \"\"\"\n  # Tokenize questions and queries separately\n  model_inputs = tokenizer(examples[\"question\"], padding=\"max_length\", truncation=True, max_length=max_length) #using 110% of the max percentile length for padding\n  labels = tokenizer(examples[\"query\"], padding=\"max_length\", truncation=True, max_length=max_length)\n\n  # Replace padding token id in labels by -100 so it's ignored by the loss function.\n  labels[\"input_ids\"] = [\n      [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n  ]\n\n  model_inputs[\"labels\"] = labels[\"input_ids\"]\n  return model_inputs\n\n# Apply the tokenization function to the training and validation datasets\ntokenized_train_dataset = sampled_train.map(tokenize_function, batched=True)\ntokenized_val_dataset = validation_set.map(tokenize_function, batched=True)\n\n# Remove unnecessary columns\ntokenized_train_dataset = tokenized_train_dataset.remove_columns([\"db_id\", \"query\", \"question\", \"query_toks\", \"query_toks_no_value\", \"question_toks\"])\ntokenized_val_dataset = tokenized_val_dataset.remove_columns([\"db_id\", \"query\", \"question\", \"query_toks\", \"query_toks_no_value\", \"question_toks\"])\n\nmini_val_dataset = tokenized_val_dataset.select(random.sample(range(len(tokenized_val_dataset)), 5)) #Will be used to evaluate during training to reduce memory requirements and speed up training\n\n# Print a sample to check the format\nprint(tokenized_train_dataset[0])","metadata":{"_uuid":"05026de1-9dc5-473b-9f38-29127e57c6a2","_cell_guid":"0c8a02d6-997d-4f64-be72-f03be97b0559","collapsed":false,"id":"dtzEK1k9ekPy","outputId":"985d2447-5eb7-4a9f-86a8-7764dfebc663","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:50:53.027698Z","iopub.execute_input":"2024-09-05T08:50:53.028461Z","iopub.status.idle":"2024-09-05T08:50:54.448288Z","shell.execute_reply.started":"2024-09-05T08:50:53.028421Z","shell.execute_reply":"2024-09-05T08:50:54.447376Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a15bd493b94d0d8f3e0fcfb29c4a67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1034 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a43ea9201f047f681555c205f9b4fcb"}},"metadata":{}},{"name":"stdout","text":"{'input_ids': [128000, 3923, 527, 682, 279, 2204, 1176, 5144, 315, 279, 12050, 889, 527, 304, 2361, 439, 11509, 323, 2834, 30, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [128000, 4963, 60186, 350, 16, 55669, 609, 4393, 12050, 5871, 350, 16, 13369, 5696, 2752, 826, 5871, 350, 17, 6328, 350, 16, 21491, 307, 284, 350, 17, 21491, 307, 5401, 350, 17, 6318, 284, 220, 16, 3651, 350, 17, 1444, 1354, 284, 220, 16, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Configure LoRA and Load Model\nThis code section sets up LoRA (Low-Rank Adaptation) for efficient fine-tuning and loads the pre-trained Llama 3.1 8B Instruct model. We define the LoRA configuration using LoraConfig, specifying parameters like rank, scaling factor, target modules (attention layers), and dropout. The pre-trained model is loaded in 8-bit precision to save memory and automatically placed on available hardware using device_map=\"auto\". Finally, we wrap the loaded model with LoRA adapters using get_peft_model, preparing it for fine-tuning with reduced parameter updates.","metadata":{"_uuid":"5f8051c0-ec42-4160-8428-959c6f32cd02","_cell_guid":"69d5c382-e7e8-4daf-b373-455265146fab","id":"2gjiuh6x3YIh","trusted":true}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\nfrom transformers import AutoModelForCausalLM, BitsAndBytesConfig\n\nos.environ[\"BNB_4BIT_COMPUTE_DTYPE\"] = \"torch.float16\" #To use FP16 for computations within the 4-bit layers. Default is 32 which can be slower while training\n\n# Define your custom cache directory\ncustom_cache_dir = \"/hf_model_cache/\"\n\n# Define LoRA configuration\nlora_config = LoraConfig(\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    bias=\"none\"\n)\n\n\n# Load pre-trained model\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n    quantization_config=quantization_config,\n    device_map=\"auto\",\n    token=os.environ[\"HUGGING_FACE_HUB_TOKEN\"],\n    cache_dir=custom_cache_dir,\n)\n\n# Wrap the model with LoRA\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"_uuid":"c35d53cf-9ef8-4101-807e-800790c501dd","_cell_guid":"8bab335d-9039-4525-b9f4-71225a0a149b","collapsed":false,"id":"c5IXEerXioQI","outputId":"be937de8-afe1-4bb7-a111-91ce887b356b","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:51:44.747503Z","iopub.execute_input":"2024-09-05T08:51:44.748456Z","iopub.status.idle":"2024-09-05T08:53:48.259090Z","shell.execute_reply.started":"2024-09-05T08:51:44.748416Z","shell.execute_reply":"2024-09-05T08:53:48.258135Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfabbf681140491f9d27c8c390858496"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e94ed40ca03041a5a4d57ea2d9a96e8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5bdf4c85c82442292bb562e5f546a63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58f51aaae74849868a1e3a6380f1cdcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae64264498cb4364be4061993f49cffa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fd0c6a34ddd4f5f9a8bb0b8d6dff3ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deafcfeda98644cea6605aa29ffa642f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b812b9fd5845fdb42941625a39abd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85278a7fa7e94e069e94d78234006334"}},"metadata":{}},{"name":"stdout","text":"trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model.config)  # Prints the model's configuration settings, including parameters, architecture, and training details.","metadata":{"_uuid":"b2101e44-222e-46a0-ae71-d31866fa352a","_cell_guid":"3d1b1a10-5db2-441f-8b0f-06f4bed3f6ee","collapsed":false,"id":"6-Z39QTbnsi9","outputId":"667a55ba-9582-4fec-a2ed-194fca21b7bc","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:57:28.760035Z","iopub.execute_input":"2024-09-05T08:57:28.760693Z","iopub.status.idle":"2024-09-05T08:57:28.767477Z","shell.execute_reply.started":"2024-09-05T08:57:28.760653Z","shell.execute_reply":"2024-09-05T08:57:28.766409Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": [\n    128001,\n    128008,\n    128009\n  ],\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 131072,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"quantization_config\": {\n    \"_load_in_4bit\": true,\n    \"_load_in_8bit\": false,\n    \"bnb_4bit_compute_dtype\": \"float32\",\n    \"bnb_4bit_quant_storage\": \"uint8\",\n    \"bnb_4bit_quant_type\": \"fp4\",\n    \"bnb_4bit_use_double_quant\": false,\n    \"llm_int8_enable_fp32_cpu_offload\": false,\n    \"llm_int8_has_fp16_weight\": false,\n    \"llm_int8_skip_modules\": null,\n    \"llm_int8_threshold\": 6.0,\n    \"load_in_4bit\": true,\n    \"load_in_8bit\": false,\n    \"quant_method\": \"bitsandbytes\"\n  },\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": {\n    \"factor\": 8.0,\n    \"high_freq_factor\": 4.0,\n    \"low_freq_factor\": 1.0,\n    \"original_max_position_embeddings\": 8192,\n    \"rope_type\": \"llama3\"\n  },\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.44.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print (model) #Prints a detailed summary of the model, including its layers, modules, and parameters.","metadata":{"_uuid":"6df1455b-47f1-4329-a74a-67c847e91fd8","_cell_guid":"23b71570-8a2a-4954-95e9-0755e2738f3d","collapsed":false,"id":"IMmGShbhGNDK","outputId":"e5c50e5f-0c34-4c2e-e580-62e198391e1a","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T08:57:29.516720Z","iopub.execute_input":"2024-09-05T08:57:29.517591Z","iopub.status.idle":"2024-09-05T08:57:29.539919Z","shell.execute_reply.started":"2024-09-05T08:57:29.517549Z","shell.execute_reply":"2024-09-05T08:57:29.538984Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"PeftModel(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Training Configuration and Setup\n\nHere we define the training parameters and creates a Trainer object for fine-tuning the Llama model.\n\n\n\n*   The TrainingArguments class from the transformers library is used to specify various hyperparameters and settings for the training process, such as the learning rate, batch size, number of epochs, and evaluation strategy.\n\n*   The Trainer class is then instantiated with the LoRA-wrapped Llama model, the training arguments, and the training and validation datasets. The Trainer object will manage the training loop, evaluation, logging, and saving of checkpoints.","metadata":{"_uuid":"e0bae9d2-8e05-457e-9c93-d49439dfbba7","_cell_guid":"bab0d5e8-18b4-4c89-a6ba-4d314248d877","id":"F-OWObpaScO2","trusted":true}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import DataCollatorForSeq2Seq\n\n\n# Define the training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./llama-lora-finetuned\", # Directory to save the fine-tuned model\n    learning_rate=1e-4,                  # Learning rate for the optimizer\n    per_device_train_batch_size=8,       # Batch size per GPU for training\n    per_device_eval_batch_size=4,        # Batch size per GPU for evaluation\n    gradient_accumulation_steps=4,\n    eval_accumulation_steps=4, \n    num_train_epochs=4,                  # Number of training epochs\n    weight_decay=0.01,                   # Weight decay for regularization\n    eval_strategy=\"steps\",               # Evaluation strategy: evaluate every 'eval_steps'\n    eval_steps=5,                        # Number of steps between evaluations\n    save_steps=5,                        # Number of steps between saving checkpoints\n    logging_steps=5,                     # Number of steps between logging training information\n    report_to=\"none\",\n    logging_strategy=\"steps\",            # Log every `logging_steps`\n#    fp16=True,                           #Useful if the model is not quantized to 4 bits\n#    metric_for_best_model=\"exact_match\", #Required only if evaluation is done on test data \n#    predict_with_generate=True,\n#    generation_num_beams=5,  # For beam search during generation\n)\n\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\n# Create the Trainer object\ntrainer = Seq2SeqTrainer(\n    model=model,                             # The LoRA-wrapped Llama model\n    args=training_args,                      # The training arguments\n    train_dataset=tokenized_train_dataset,   # The tokenized training dataset\n    eval_dataset=mini_val_dataset,           # The tokenized mini validation dataset\n#    compute_metrics=compute_metrics,         #Required for evaluation on test data\n    data_collator=data_collator,\n)","metadata":{"_uuid":"00957a8e-bfb1-455e-933a-53b584b05acf","_cell_guid":"dcae3a2a-b232-4cf5-9c1a-226094226c5d","collapsed":false,"id":"p4nYZ48SGbTd","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T09:05:44.110774Z","iopub.execute_input":"2024-09-05T09:05:44.111244Z","iopub.status.idle":"2024-09-05T09:05:44.160119Z","shell.execute_reply.started":"2024-09-05T09:05:44.111201Z","shell.execute_reply":"2024-09-05T09:05:44.159283Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model","metadata":{"_uuid":"c57c89a6-3b90-49c1-950c-9163e5079596","_cell_guid":"15f2e7d4-b10f-4d7c-a645-a564239352ac","id":"cs1nQnk7SaB_","trusted":true}},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"_uuid":"759f4517-a622-42ec-bb2a-5cbc996fb534","_cell_guid":"b02e6897-b327-4257-9320-cf6b3c24e0fa","collapsed":false,"id":"v_zV4s4_Q2qM","outputId":"d81bb32e-7669-4899-e4e6-daf572c584eb","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T09:05:46.484295Z","iopub.execute_input":"2024-09-05T09:05:46.484686Z","iopub.status.idle":"2024-09-05T09:43:19.497831Z","shell.execute_reply.started":"2024-09-05T09:05:46.484650Z","shell.execute_reply":"2024-09-05T09:43:19.496823Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 36:55, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>8.045200</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>5.868400</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>5.338300</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>5.034500</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>4.806300</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>4.701200</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>4.461700</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>4.568600</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>4.382000</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>4.331600</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>4.255000</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>4.207100</td>\n      <td>No log</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer_stats","metadata":{"execution":{"iopub.status.busy":"2024-09-05T09:51:57.646152Z","iopub.execute_input":"2024-09-05T09:51:57.646588Z","iopub.status.idle":"2024-09-05T09:51:57.653183Z","shell.execute_reply.started":"2024-09-05T09:51:57.646554Z","shell.execute_reply":"2024-09-05T09:51:57.652222Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=60, training_loss=4.999993260701498, metrics={'train_runtime': 2252.3129, 'train_samples_per_second': 0.888, 'train_steps_per_second': 0.027, 'total_flos': 1.1372652667994112e+16, 'train_loss': 4.999993260701498, 'epoch': 3.8095238095238093})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Merging LoRA Weights and Saving the Model","metadata":{}},{"cell_type":"code","source":"# Merge LoRA weights back into the base model\nmodel = model.merge_and_unload()\n\n# Save the merged model to your device\nmodel.save_pretrained(\"./llama-lora-finetuned/final_model\") \nprint(\"Merged model saved successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T09:52:00.770104Z","iopub.execute_input":"2024-09-05T09:52:00.770518Z","iopub.status.idle":"2024-09-05T09:52:48.623822Z","shell.execute_reply.started":"2024-09-05T09:52:00.770475Z","shell.execute_reply":"2024-09-05T09:52:48.622799Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Merged model saved successfully!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load the finetuned model for inferencing ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n\nmodel_path = \"./llama-lora-finetuned/final_model\"  \n\n# Define the quantization configuration (remove deprecated arguments)\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # If you're using 4-bit quantization\n)\n\n# Load the fine-tuned model with custom device map\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    device_map=\"cuda:0\",\n    quantization_config=quant_config,\n)\nprint(\"Fine-tuned model loaded successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T10:19:30.979663Z","iopub.execute_input":"2024-09-05T10:19:30.980341Z","iopub.status.idle":"2024-09-05T10:19:34.692811Z","shell.execute_reply.started":"2024-09-05T10:19:30.980298Z","shell.execute_reply":"2024-09-05T10:19:34.691834Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebd84f64e90447349a9601c6208cd4f1"}},"metadata":{}},{"name":"stdout","text":"Fine-tuned model loaded successfully!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Setup for Inference with Streaming Output","metadata":{}},{"cell_type":"code","source":"from transformers import TextIteratorStreamer\nfrom threading import Thread\n\n# Create a TextIteratorStreamer for streaming output\nstreamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n\n# Define a function for inference\ndef generate_sql(question):\n    # Tokenize the input question\n    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n\n    # Generate text with streaming\n    generation_kwargs = dict(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],  # Include attention mask\n        streamer=streamer,\n        max_new_tokens=200,  # Adjust as needed\n        temperature=0.5,  # Control randomness\n        top_p=0.7,  # Nucleus sampling\n        num_beams=1,  # Beam search for better quality\n        early_stopping=True,  # Stop early if all beams finish\n        do_sample=False,  # Disable sampling for more focused output\n        length_penalty=2,  # Penalize longer outputs\n        repetition_penalty=1.5,\n    )\n    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n    thread.start()\n\n    # Print the streamed output\n    for new_text in streamer:\n        print(new_text, end=\"\", flush=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T10:59:57.456211Z","iopub.execute_input":"2024-09-05T10:59:57.456585Z","iopub.status.idle":"2024-09-05T10:59:57.464782Z","shell.execute_reply.started":"2024-09-05T10:59:57.456552Z","shell.execute_reply":"2024-09-05T10:59:57.463743Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"# Run Inference","metadata":{}},{"cell_type":"code","source":"# Example usage\nquestion = \"You are sql expert. Write a good useful SQL Query for this: Show name, country, age for all singers ordered by age from the oldest to the youngest.\"\nprint(f\"Question: {question}\")\nprint(\"Generated SQL:\")\ngenerate_sql(question) ","metadata":{"_uuid":"97543d47-1047-440c-9016-0c8093877ecc","_cell_guid":"0b6c1243-3a8f-44a8-ba74-95bb6b577ae3","collapsed":false,"id":"mduF46GsULRT","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-09-05T10:59:58.952132Z","iopub.execute_input":"2024-09-05T10:59:58.952539Z","iopub.status.idle":"2024-09-05T11:00:16.683455Z","shell.execute_reply.started":"2024-09-05T10:59:58.952502Z","shell.execute_reply":"2024-09-05T11:00:16.682683Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: You are sql expert. Write a good useful SQL Query for this: Show name, country, age for all singers ordered by age from the oldest to the youngest.\nGenerated SQL:\n \nSELECT * FROM Singers ORDER BY Age DESC;\nThis query will return ALL columns of Singer table and order them in descending (oldest first) based on 'Age' column.\n\nHowever if you want only Name, Country  AND AGE then use\n SELECT NAME,Country,Age   FROM SINGERS    Order By Age Desc; \n\nIf we need more than one singer with same max(age), how can I get it?  \nTo fetch multiple rows where there is tie or duplicate value at top i.e., maximum values.\nWe have already seen that MAX() function returns single row which has highest/maximum date but what about when two records exist having equal Max(date). In such cases our previous approach fails because as soon as second record exists whose Date =Max(Date )then result set becomes empty whereas actual expected output should be both these dates since they share common attribute \"Date\". To handle above situation We'll make little modification using subquery inside IN operator like below:\n\n```sql\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"_uuid":"37b200bf-fc5a-4dd6-b20e-57a2be2384fb","_cell_guid":"74a0d21f-3d86-4971-a553-79a05bdb2201","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}